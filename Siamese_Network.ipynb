{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6ce618e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import PIL.ImageOps\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc720a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(img, text = None):\n",
    "    img = img.numpy()\n",
    "    plt.axis(\"off\")\n",
    "    if text != None:\n",
    "        plt.text(75, 8, text, style = \"italic\", fontweight = \"bold\",\n",
    "                bbox = {\"facecolor\": \"white\", \"alpha\": 0.8, \"pad\": 10})\n",
    "    plt.imshow(np.transpose(img, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "def plot(iteration, loss):\n",
    "    plt.plot(iteration, loss)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef36a8c",
   "metadata": {},
   "source": [
    "### Training 부분\n",
    "1. SiameseNetworkDataset: 2개의 input을 준다. 하나는 Anchor에 해당, 다른 하나는 positive class의 이미지 혹은 negative class의 이미지\n",
    "2. DataLoader 설정 및 학습 진행."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50febbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNetworkDataset(Dataset):\n",
    "    def __init__(self,imageFolderDataset,transform=None):\n",
    "        self.imageFolderDataset = imageFolderDataset    \n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        img0_tuple = random.choice(self.imageFolderDataset.imgs)\n",
    "\n",
    "        #We need to approximately 50% of images to be in the same class\n",
    "        should_get_same_class = random.randint(0,1)\n",
    "        # 같은 class인 경우\n",
    "        if should_get_same_class:\n",
    "            while True:\n",
    "                # 같은 class의 이미지가 발견될 때까지 반복한다.\n",
    "                img1_tuple = random.choice(self.imageFolderDataset.imgs) \n",
    "                if img0_tuple[1] == img1_tuple[1]:\n",
    "                    break\n",
    "        else:\n",
    "\n",
    "            while True:\n",
    "                # 다른 클래스의 image를 찾을 때 까지 반복한다\n",
    "                img1_tuple = random.choice(self.imageFolderDataset.imgs) \n",
    "                if img0_tuple[1] != img1_tuple[1]:\n",
    "                    break\n",
    "        # image를 GrayScle로 변환\n",
    "        img0 = Image.open(img0_tuple[0]).convert(\"L\")\n",
    "        img1 = Image.open(img1_tuple[0]).convert(\"L\")\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img0 = self.transform(img0)\n",
    "            img1 = self.transform(img1)\n",
    "        \n",
    "        # images, labels.\n",
    "        return img0, img1, torch.from_numpy(np.array([int(img1_tuple[1] != img0_tuple[1])], dtype=np.float32))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imageFolderDataset.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebae7586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder 별로 labeling이 된다.\n",
    "# tuple 형태로 load가 된다. 0번 index는 image 정보, 1번 index는 label에 해당한다.\n",
    "# siamese_dataset: img0: anchor image, img1: 비교 image, tuple의 마지막: tensor([0.]) or tensor([1.]) -> 같으면 0, 다르면 1\n",
    "folder_dataset = datasets.ImageFolder(root = \"./PubFig/test\")\n",
    "transformation = transforms.Compose([transforms.Resize([100, 100]),\n",
    "                                    transforms.ToTensor()])\n",
    "siamese_dataset = SiameseNetworkDataset(imageFolderDataset = folder_dataset,\n",
    "                                       transform = transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579a2bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 간단한 dataloader 생성(visualization까지 진행)\n",
    "# 이 부분은 학습에 직접적으로 이용되지는 않는다.\n",
    "dataloader = DataLoader(siamese_dataset, shuffle = True, num_workers = 0, batch_size = 2)\n",
    "example_batch = next(iter(dataloader))\n",
    "concat_data = torch.cat((example_batch[0], example_batch[1]), 0)\n",
    "show_img(torchvision.utils.make_grid(concat_data))\n",
    "print(example_batch[2].numpy().reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e85616c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function의 경우는 Contrastive Loss를 이용\n",
    "# loss나 모델 자체는 굉장히 단순하다. load를 시켰을 때 가벼운 모델이면 좋겠다.\n",
    "class SiameseNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SiameseNet, self).__init__()\n",
    "        # convolution 1\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=96, stride=4, kernel_size=11),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(3, stride=2)\n",
    "        )\n",
    "        # convolution 2\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=96, out_channels=256, stride=1, kernel_size=5),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, stride=2)\n",
    "        )\n",
    "        # convolution 3\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256, out_channels=384, stride=1, kernel_size=3),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        # fully connected\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(384, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(1024, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, 2)\n",
    "        )\n",
    "        # he initalization\n",
    "        torch.nn.init.kaiming_normal_(self.fc[0].weight)\n",
    "        torch.nn.init.kaiming_normal_(self.fc[2].weight)\n",
    "        torch.nn.init.kaiming_normal_(self.fc[4].weight)\n",
    "\n",
    "    def forward_one(self, x):\n",
    "        output = self.conv1(x)\n",
    "        output = self.conv2(output)\n",
    "        output = self.conv3(output)\n",
    "        # flatten\n",
    "        output = output.view(output.size()[0], -1)\n",
    "        output = self.fc(output)\n",
    "        return output\n",
    "    \n",
    "    def forward(self, input1, input2):\n",
    "        # fully connected를 통과한 최종 vector가 얻어진다.\n",
    "        # 추후에 이것이 괜찮으면 최종 결과를 저장하는 방식으로 진행한다.\n",
    "        output1 = self.forward_one(input1)\n",
    "        output2 = self.forward_one(input2)\n",
    "        return output1, output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0d65e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contrastive Loss를 이용한다.\n",
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self, margin = 1.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "    \n",
    "    def forward(self, output1, output2, label):\n",
    "        euclidean = F.pairwise_distance(output1, output2, keepdim = True)\n",
    "        contrastive = torch.mean((1-label) * torch.pow(euclidean, 2) +\n",
    "                                (label) * torch.pow(torch.clamp(self.margin - euclidean, min=0.0), 2))\n",
    "        return contrastive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d140c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(siamese_dataset, shuffle = True, batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbc1544",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# model = SiameseNet().to(device)\n",
    "criterion = ContrastiveLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr = 1e-3)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode = \"min\", factor = 0.5, threshold_mode = \"abs\", min_lr = 1e-7, verbose = True, patience = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4652d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21b6ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "iteration_num = 0\n",
    "count = []\n",
    "best_model = None\n",
    "bestloss = 1\n",
    "loss_check = []\n",
    "for epoch in range(200):\n",
    "    # i는 iteration number에 해당한다.\n",
    "    model.train()\n",
    "    for i, (img0, img1, label) in tqdm(enumerate(train_dataloader, 0)):\n",
    "        img0, img1, label = img0.to(device), img1.to(device), label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out1, out2 = model(img0, img1)\n",
    "        # label의 경우는 positive면 1, negative면 0\n",
    "        loss_ = criterion(out1, out2, label)\n",
    "        loss_check.append(loss_.item())\n",
    "        if loss_ < bestloss:\n",
    "            bestloss = loss_\n",
    "            best_model = model\n",
    "        loss_.backward()\n",
    "        optimizer.step()\n",
    "        if i%10 == 0:\n",
    "            iteration_num += 10\n",
    "            count.append(iteration_num)\n",
    "            losses.append(loss_.item())\n",
    "            print(\"epoch {}th, Current iteration Loss: {}\".format(epoch, loss_.item()))\n",
    "    check_loss = np.mean(loss_check)\n",
    "    scheduler.step(check_loss)\n",
    "plot(count, losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072a9195",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"./rough.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c242db70",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafe2e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_test = datasets.ImageFolder(root = \"./PubFig/test/\")\n",
    "testset = SiameseNetworkDataset(imageFolderDataset=folder_test, transform=transformation)\n",
    "test_loader = DataLoader(testset, num_workers = 0, batch_size = 1, shuffle = False)\n",
    "dataiter = iter(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c13dc3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.cpu()\n",
    "    model.eval()\n",
    "    x0, _, _ = next(dataiter)\n",
    "    for i in range(5):\n",
    "        _, x1, label = next(dataiter)\n",
    "        concatenated = torch.cat((x0, x1), 0)\n",
    "        out1, out2 = model(x0, x1)\n",
    "        euc = F.pairwise_distance(out1, out2)\n",
    "        show_img(torchvision.utils.make_grid(concatenated), f\"Dissimilarity:{euc.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcc0bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"./rough.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4ca22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(best_model, \"./best_model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625dc763",
   "metadata": {},
   "source": [
    "### Sample을 통한 결과치 명시\n",
    "여기서부터는 예시를 보여줄 예정.(실행 시켜보고 싶으면 실행 시켜본다.)\n",
    "1. x = torch.randn([batch_size, channel, width, height])\n",
    "2. x라는 임의의 tensor 생성\n",
    "3. 형태는 1 * 2 matrix 생성(fully connected 통과 후)\n",
    "4. tensor([[-0.3888,  0.3707]])와 같은 결과가 나오게 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb76274",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # convolution 1\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=96, stride=4, kernel_size=11),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(3, stride=2)\n",
    "        )\n",
    "        # convolution 2\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=96, out_channels=256, stride=1, kernel_size=5),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, stride=2)\n",
    "        )\n",
    "        # convolution 3\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256, out_channels=384, stride=1, kernel_size=3),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        # fully connected\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(384, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(1024, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, 2)\n",
    "        )\n",
    "        # he initalization\n",
    "        torch.nn.init.kaiming_normal_(self.fc[0].weight)\n",
    "        torch.nn.init.kaiming_normal_(self.fc[2].weight)\n",
    "        torch.nn.init.kaiming_normal_(self.fc[4].weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        out = self.conv3(out)\n",
    "        out = out.view(out.size()[0], -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beca6fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실행 시켜보면 알겠지만 1 * 2 tensor가 결과로 출력된다.\n",
    "x = torch.randn([1, 1, 100, 100])\n",
    "net = Net()\n",
    "net = Net()\n",
    "with torch.no_grad():\n",
    "    net.eval()\n",
    "    print(net(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f75181",
   "metadata": {},
   "source": [
    "### 하나의 image에 대한 신경망 통과 최종 결과를 뽑기 위한 과정\n",
    "이 부분 부터 사실상 시작하면 된다. \n",
    "1. SiameseNetworkDatasetInference로 Data를 우선 구성\n",
    "2. dataloader의 batch size는 1개로 진행\n",
    "3. 우선 학습 자체는 2개의 input으로 진행했다. 따라서 2개의 input을 주되 out을 1개만 받는 쪽으로 가닥을 잡는다.\n",
    "4. 데이터셋 구성 역시 이에 따라 다르게 진행한다. 1개는 진짜 image, 다른 하나는 random 한 것.\n",
    "4. 그리고 euclidean 거리를 통해서 유사도 비교를 진행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c2485a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model load.\n",
    "# 학습 때와는 달리 1개의 output만 낸다.\n",
    "class SiameseNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SiameseNet, self).__init__()\n",
    "        # convolution 1\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=96, stride=4, kernel_size=11),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(3, stride=2)\n",
    "        )\n",
    "        # convolution 2\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=96, out_channels=256, stride=1, kernel_size=5),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, stride=2)\n",
    "        )\n",
    "        # convolution 3\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256, out_channels=384, stride=1, kernel_size=3),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        # fully connected\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(384, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(1024, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, 2)\n",
    "        )\n",
    "        # he initalization\n",
    "        torch.nn.init.kaiming_normal_(self.fc[0].weight)\n",
    "        torch.nn.init.kaiming_normal_(self.fc[2].weight)\n",
    "        torch.nn.init.kaiming_normal_(self.fc[4].weight)\n",
    "\n",
    "    def forward_one(self, x):\n",
    "        output = self.conv1(x)\n",
    "        output = self.conv2(output)\n",
    "        output = self.conv3(output)\n",
    "        # flatten\n",
    "        output = output.view(output.size()[0], -1)\n",
    "        output = self.fc(output)\n",
    "        return output\n",
    "    \n",
    "    def forward(self, input1, input2):\n",
    "        # output을 1개만 받는다.\n",
    "        output1 = self.forward_one(input1)\n",
    "        output2 = self.forward_one(input2)\n",
    "        return output1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b5054d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"./rough.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b11ea2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추론을 위한 dataset 구성\n",
    "class SiameseNetworkDatasetInference(Dataset):\n",
    "    def __init__(self,imageFolderDataset,transform=None):\n",
    "        self.imageFolderDataset = imageFolderDataset    \n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        # self.imageFolderDataset.imgs -> tuple 형태: image file 경로, label 정보\n",
    "        img0_ = self.imageFolderDataset.imgs\n",
    "        img0_ = img0_[index]\n",
    "        img0 = Image.open(img0_[0]).convert(\"L\")\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img0 = self.transform(img0)\n",
    "        \n",
    "        # 기본적으로 SiameseNetwork를 학습 시킬 때, 2개의 image를 input으로 받아 학습을 돌린다.\n",
    "        # 학습 외적으로 최종 output을 뽑고 싶으면 임의의 tensor를 생성한 후 같이 return을 시키고 따로 사용하지 않는다.\n",
    "        random_tensor = torch.randn([1, 100, 100])\n",
    "        return img0, random_tensor\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imageFolderDataset.imgs)\n",
    "\n",
    "# root에 test 시켜볼 파일 넣을 것.\n",
    "# label 별로 이미지가 들어 있기만 하면 된다.\n",
    "folder_dataset = datasets.ImageFolder(root = \"./PubFig/test\")\n",
    "transformation = transforms.Compose([transforms.Resize([100, 100]),\n",
    "                                    transforms.ToTensor()])\n",
    "infer_dataset = SiameseNetworkDatasetInference(imageFolderDataset = folder_dataset,\n",
    "                                       transform = transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81a91b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 확인 결과 folder_dataset의 순서와 infer_dataset의 순서가 같다.(shuffle = False로 둠)\n",
    "infer_dataloader = DataLoader(infer_dataset, shuffle = False, batch_size = 1)\n",
    "dataiter = iter(infer_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00a522c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_ftr에는 이미지 별로 뽑아낸 신경망 통과한 결과가 들어가게 된다.\n",
    "add_ftr = []\n",
    "for i in range(len(dataiter)):\n",
    "    with torch.no_grad():\n",
    "        model.cpu()\n",
    "        model.eval()\n",
    "        # input으로 x0의 경우는 GrayScale 사진, x1은 임의의 Tensor\n",
    "        x0, x1 = next(dataiter)\n",
    "        add_ftr.append(model(x0, x1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed4224b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 1.3045, -0.1385]]),\n",
       " tensor([[ 1.3343, -0.1551]]),\n",
       " tensor([[0.5642, 0.5259]]),\n",
       " tensor([[0.5074, 0.5806]]),\n",
       " tensor([[-0.2092,  1.0821]]),\n",
       " tensor([[-0.2925,  0.9744]]),\n",
       " tensor([[0.4742, 0.3726]]),\n",
       " tensor([[0.4515, 0.3274]])]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 각 이미지 별 거리 기반 전\n",
    "add_ftr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d1384bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9750])\n",
      "tensor([1.0091])\n",
      "tensor([0.1777])\n",
      "tensor([0.2105])\n",
      "tensor([0.9851])\n",
      "tensor([0.9746])\n",
      "tensor([1.4142e-06])\n",
      "tensor([0.0507])\n"
     ]
    }
   ],
   "source": [
    "# 이 부분은 준비한 test set에 따라 달라진다.\n",
    "# 기본적으로 pariwise_distance(anchor, compare)\n",
    "for i in range(8):\n",
    "    # 앞에는 anchor, 뒤에는 비교 이미지\n",
    "    print(F.pairwise_distance(add_ftr[6], add_ftr[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47177727",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
